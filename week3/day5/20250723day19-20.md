# 19, 20일차(2025.07.23)
## 개요
- 유의미하지 않은 변수를 골라내어 단순한 모델 만들기
## 학습 내용
### 진도
- 지난시간 결과로 성별코드가 유의미하지 않은 변수로 작용함을 밝힘.

**1. 회귀 모델 2개 학습**
- `model2` : 성별코드 포함한 모델
```python
a=df[['운동빈도', '보충제코드', '나이', '성별코드', '월구독료']]
a=sm.add_constant(a)
b=df['건강점수']
model2=sm.OLS(b,a).fit()
print(model2.summary())
b_pred = model2.predict(a)
```
- `model3` : 성별코드 제거한 모델
```python
p=df[['운동빈도', '보충제코드', '나이', '월구독료']]
z=sm.add_constant(p)
q=df['건강점수']
model3=sm.OLS(q,z).fit()
print(model3.summary())
q_pred=model3.predict(z)
```
---
**2. 모델 비교**
- `model2` 성능 평가
```python
#통계적 수치 확인
print(model2.summary())

#평균제곱오차, r2 측정
def raw_predict_ols(df):
    mse=mean_squared_error(b, b_pred)
    rmse=np.sqrt(mse)
    r2=r2_score(b,b_pred)
    print('RMSE :', rmse)
    print('R2 :', r2)
```
- `model3` 성능 평가
```python
#통계적 수치 확인
print(model3.summary())

#평균제곱오차, r2 측정
def new_predict_ols(df):
    mse=mean_squared_error(q, q_pred)
    rmse=np.sqrt(mse)
    r2=r2_score(q,q_pred)
    print('RMSE :', rmse)
    print('R2 :', r2)
```
- 결과
```python
              model2    model3
Unnamed: 0
R-squared     0.7810    0.7830 #R-squared : 예측 설명력(ex. 건강점수의 78.3%는 이 입력변수들로 설명 가능)
AIC         620.4000  618.5000 #AIC : 모델의 복잡도와 성능을 동시에 따졌을 때, 얼마나 좋은 모델인지. 작을수록 좋다.(성능 좋고 복잡도가 적음)
BIC         636.1000  631.5000 #BIC : AIC와 같은 개념이지만, 변수의 수에 더 강한 패널티를 준다. 작을수록 좋다(간단한 모델인데 성능도 좋다는 것을 뜻함)
RMSE          5.0695    5.0699 
R2            0.7920    0.7920 
```

**3. 잔차 시각화**
```python
import matplotlib.pyplot as plt
import matplotlib
import scipy.stats as stats
import statsmodels.api as sm
import seaborn as sns

matplotlib.rc('font', family='Malgun Gothic')
matplotlib.rcParams['axes.unicode_minus']=False

residuals=q-q_pred
```
```python
# 히스토그램, qqplot, 예측값 vs 잔차 산점도 함수
def residual_visual(df):
    plt.figure(figsize=(15,5))

    plt.subplot(1,3,1)
    sns.histplot(residuals, bins=20, kde=True)
    plt.title('잔차 분포 히스토그램')
    plt.xlabel('잔차')
    plt.ylabel('빈도')

    plt.subplot(1,3,2)
    sm.qqplot(residuals,fit=True, line='45', ax=plt.gca())
    plt.title('잔차 q-q plot')
    
    plt.subplot(1,3,3)
    plt.scatter(q_pred, residuals)
    plt.axhline(0, color='red', linestyle='--')
    plt.title('예측값 vs 잔차')
    plt.xlabel('예측값')
    plt.ylabel('잔차')

    plt.tight_layout()
    plt.show()
residual_visual(df)
```
[잔차 비교 그래프](잔차비교그래프.png)

해석
- 히스토그램 : 정규분포 모양을 만족하고, 극단적임 첨도, 왜도가 존재하지 않는다. 따라서 정규성을 만족
- Q-Q plot : 빨간선 위에 값들이 몰림. 정규성 만족
- 예측값 vs 잔차 산점도 : 잔차가 골고루 퍼지고, 분산도 거의 일정하다. 등분산성과 선형성을 만족